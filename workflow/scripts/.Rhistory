rowV13 = primer1[ which(primer1$Taxonomy == currentTaxa), ]
rowV13$Taxonomy = NULL
rowV13$OTU_ID = NULL
rowV13 = colSums(rowV13) %>% t(.) %>% as.data.frame(.)
rowV45 = primer2[ which(primer2$Taxonomy == currentTaxa), ]
rowV45$Taxonomy = NULL
rowV45$OTU_ID = NULL
rowV45 = colSums(rowV45) %>% t(.) %>% as.data.frame(.)
if (dim(rowV45)[1] == 0){
test[x,] = rowV13 # If the rowV45 is empty, then add the V13 row
} else if (dim(rowV13)[1] == 0){
test[x,] = rowV45 # If the rowV13 is empty, then add the V45 row
} else { # Meaning, the taxa exists in both tables
V13count = rowV13 %>% as.numeric(.) %>% dplyr::na_if(0) %>% as.data.frame(.)
V45count = rowV45 %>% as.numeric(.) %>% dplyr::na_if(0) %>% as.data.frame(.)
meansOfRow = rowMeans(cbind(V13count,V45count),na.rm=TRUE) %>% round(.) # Meaning, if any of them has NA, then just report the normal number, then round everything
meansOfRow[is.nan(meansOfRow)] = 0 # If na is present in both, then NaN will be reported, in this case, it means both rows had zeros, so just return it back to zero
test[x,] = c(currentTaxa,meansOfRow)
}
}
suppressMessages(library("optparse"))
suppressMessages(library("dada2"))
inputFolder = "/Users/khaled/Downloads/metabolic syndrome/favabean/Run1-V34/dada2/filtered"
rDirection = "R1"
cores = 18
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
theFiles
inputFolder = "/Users/khaled/Downloads/metabolic syndrome/favabean/Run1-V34/dada2"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
theFiles
theFiles
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 1)
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
rDirection = "R2"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 1)
cores = 18
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 1)
library("dada2")
?learnErrors
inputFolder = "~/Desktop/metabolic syndrome/favabean/Batch1-V34/dada2/"
rDirection = "R2"
rDirection = "R1"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
cores = 19
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
packageVersion("dada2")
R
#!usr/bin/env Rscript
# Function to read the first header from a FASTQ file
read_first_fastq_header = function(file_path) {
con = file(file_path, "r")
first_header = readLines(con, n = 1)
close(con)
return(first_header)
}
# Function to extract and parse header parts
parse_header = function(header) {
parts = strsplit(header, ":")[[1]]
return(paste(parts[1:4], collapse = ":"))
}
#!usr/bin/env Rscript
library(ShortRead)
library(tidyverse)
# Function to read the first header from a FASTQ file
read_first_fastq_header = function(file_path) {
con = readFastq(file_path)
return(con)
}
# Function to extract and parse header parts
parse_header = function(header) {
parts = strsplit(header, ":")[[1]]
return(paste(parts[1:4], collapse = ":"))
}
fastq_dir = "~/Desktop/sequences/" # Directory containing your FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.fastq.gz", full.names = TRUE) # Get a list of FASTQ files
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
sample_info = read.csv("~/Desktop/sequences/files_info.csv")
# Initialize a vector to store parsed headers
all_headers = data.frame(filename=NA, batchID=NA)
# Process each FASTQ file
for (file in fastq_files) {
header = read_first_fastq_header(file)
header = as.character(header@id[1])
parsed_header = parse_header(header)
all_headers = rbind(data.frame(filename=file, batchID=parsed_header), all_headers)
}
# Count unique headers
theCount = table(all_headers$batchID)
theCount = data.frame(theCount)
theCount = data.frame(sequenceID=theCount$Var1, batch=paste0("Batch", 1:nrow(theCount)))
# Merge all_headers with theCount
all_headers = merge(all_headers, theCount, by.x="batchID", by.y="sequenceID")
# Keep only the file names and not the path of the files
all_headers$filename = sub(".*/", "", all_headers$filename)
# Rename columns
colnames(all_headers) = c("batchID", "fastq1", "Batch_ID")
all_headers$batchID = NULL
# Remove Batch_ID from sample_info if it exists
sample_info$Batch_ID = NULL
# Join all_headers with sample_info to add Batch_ID
sample_info = merge(sample_info, all_headers, by.x="fastq1", by.y="fastq1", all.x=TRUE)
# Output to a file
write.csv(sample_info, file = "~/Desktop/sequences/files_info.csv", row.names = FALSE, quote = FALSE)
suppressMessages(library("optparse"))
suppressMessages(library("dada2"))
opt = NULL
opt$input = "~/Desktop/sequences/favabean/Batch1-27F_FwR1519R_RvR2/dada2/"
rDirecion = "R2"
cores = 20
opt$rdirecion = "R2"
opt$cores = 20
inputFolder = opt$input
rDirection = opt$rdirection
cores = as.numeric(opt$cores)
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
theFiles
rDirection
rDirection = "R2"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
theFiles
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
inputFolder
rDirection
paste0(inputFolder,"_DADA2Errors-",rDirection,".RData")
inputFolder
inputFolder = "~/Desktop/sequences/favabean/Batch1-515bF_TruSeqF926R_TruSeqR/dada2/"
inputFolder = opt$input
opt = NULL
inputFolder
opt$input = inputFolder
opt$rdirection = "R1"
opt$cores = 20
inputFolder = opt$input
rDirection = opt$rdirection
cores = as.numeric(opt$cores)
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
rDirection = "R2"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
inputFolder
inputFolder = "~/Desktop/sequences/favabean/Batch1-multiples/dada2/"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
rDirection
rDirection = "R1"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
inputFolder = "~/Desktop/sequences/favabean/Batch2-27F_FwR1519R_RvR2/dada2/"
rDirection
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
rDirection
rDirection = "R2"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
inputFolder = "~/Desktop/sequences/favabean/Batch2-515bF_TruSeqF926R_TruSeqR/dada2/"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
rDirection
rDirection = "R1"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
inputFolder = "~/Desktop/sequences/favabean/Batch2-multiples/dada2/"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
rDi
rDirection = "R2"
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
cores = 20
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
opt = NULL
opt$input = "/Users/khaled/Desktop/sequences/favabean/Batch1-27F_FwR1519R_RvR2/dada2/dada2_DADA2Errors-R1.RData"
cores = 20
rDirection = "R1"
dadaDenoised = dada(theFiles, err=DADA2errors, multithread=cores, pool=TRUE, verbose=2)
rm(opt,cores)
save(dadaDenoised, theFiles, inputFolder,file = paste0(inputFolder,"_DADA2Denoise-",rDirection,".RData"), envir = .GlobalEnv)
paste0(inputFolder,"_DADA2Denoise-",rDirection,".RData")
inputFolder = "~/Desktop/sequences/favabean/Batch1-27F_FwR1519R_RvR2/dada2/"
rDirection = "R2"
cores = 20
rDirection
theFiles = sort(list.files(paste0(inputFolder,"/filtered"), pattern=paste0(rDirection,".*fastq.*"), full.names = TRUE, recursive = TRUE))
print("DADA2 Filtered and trimmed fastq files found")
print(theFiles)
print(paste("Will now run DADA2 Error learning. Number of cores to be utilized:",cores))
DADA2errors = learnErrors(theFiles, randomize=TRUE, multithread = cores, verbose = 2)
print("DADA2 Errors learned")
rm(cores,opt)
save(DADA2errors, inputFolder, theFiles, file = paste0(inputFolder,"_DADA2Errors-",rDirection,".RData"), envir = .GlobalEnv)
load("/Users/khaled/Desktop/sequences/favabean/Batch1-27F_FwR1519R_RvR2/dada2/_DADA2Errors-R1.RData")
cores = 20
rDirection = "R1"
dadaDenoised = dada(theFiles, err=DADA2errors, multithread=cores, pool=TRUE, verbose=2)
theFiles
load("/Users/khaled/Desktop/sequences/favabean/Batch1-27F_FwR1519R_RvR2/dada2/_DADA2Errors-R2.RData")
rDirection = "R2"
dadaDenoised = dada(theFiles, err=DADA2errors, multithread=cores, pool=TRUE, verbose=2)
dadaDenoised = dada(theFiles, err=DADA2errors, multithread=cores, pool="pseudo", verbose=2)
dadaDenoised = dada(theFiles, err=DADA2errors, multithread=cores, pool=FALSE, verbose=2)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("dada2"))
opt = NULL
opt$input = "/Users/khaled/Desktop/sequences/multiples_ChimRem_ASVcondensed.tsv"
opt$cores = 20
inputFile = opt$input
cores = opt$cores
load(inputFile)
read_tsv(inputFile)
inputfile4 = read_tsv(inputFile)
condensed_table = collapseNoMismatch(inputfile4, minOverlap = 20, orderBy = "abundance", identicalOnly = FALSE, vec = TRUE, band = -1, verbose = TRUE)
inputfile4 = read_tsv(inputFile) %>% as.data.frame(.)
condensed_table = collapseNoMismatch(inputfile4, minOverlap = 20, orderBy = "abundance", identicalOnly = FALSE, vec = TRUE, band = -1, verbose = TRUE)
#!usr/bin/env Rscript
library("tidyverse")
# Function to read the first header from a FASTQ file
read_first_fastq_header = function(file_path) {
con = gzfile(file_path, "r")
first_header = readLines(con, n = 1)
close(con)
return(first_header)
}
# Function to extract and parse header parts
parse_header = function(header) {
parts = strsplit(header, ":")[[1]]
return(paste(parts[1:4], collapse = ":"))
}
fastq_dir = "/Users/khaled/Desktop/sequencers_part2/Andrew/"
fastq_dir = "/data/" # Directory containing your FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.gz$", full.names = TRUE) # Get a list of FASTQ files in gz format
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
sample_info = read.csv("/Users/khaled/Desktop/sequencers_part2/Andrew/files_info.csv")
all_headers = data.frame(filename=NA, batchID=NA)
# Process each FASTQ file
for (file in fastq_files) {
header = read_first_fastq_header(file)
parsed_header = parse_header(header)
all_headers = rbind(data.frame(filename=file, batchID=parsed_header), all_headers)
}
# Count unique headers
theCount = table(all_headers$batchID)
theCount = data.frame(theCount)
theCount = data.frame(sequenceID=theCount$Var1, batch=paste0("Batch", 1:nrow(theCount)))
fastq_files = list.files(fastq_dir, pattern = "\\.gz$", full.names = TRUE) # Get a list of FASTQ files in gz format
fastq_dir = "/Users/khaled/Desktop/sequencers_part2/Andrew/"
fastq_files = list.files(fastq_dir, pattern = "\\.gz$", full.names = TRUE) # Get a list of FASTQ files in gz format
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
fastq_files
# Initialize a vector to store parsed headers
all_headers = data.frame(filename=NA, batchID=NA)
# Process each FASTQ file
for (file in fastq_files) {
header = read_first_fastq_header(file)
parsed_header = parse_header(header)
all_headers = rbind(data.frame(filename=file, batchID=parsed_header), all_headers)
}
# Count unique headers
theCount = table(all_headers$batchID)
theCount = data.frame(theCount)
theCount = data.frame(sequenceID=theCount$Var1, batch=paste0("Batch", 1:nrow(theCount)))
# Merge all_headers with theCount
all_headers = merge(all_headers, theCount, by.x="batchID", by.y="sequenceID")
# Keep only the file names and not the path of the files
all_headers$filename = sub(".*/", "", all_headers$filename)
# Rename columns
colnames(all_headers) = c("batchID", "fastq1", "Batch_ID")
all_headers$batchID = NULL
# Remove Batch_ID from sample_info if it exists
sample_info$Batch_ID = NULL
# Join all_headers with sample_info to add Batch_ID
sample_info = merge(sample_info, all_headers, by.x="fastq1", by.y="fastq1", all.x=TRUE)
# Now make the Sample column unique and add an alias column
sample_info$alias = as.character(sample_info$sample) %>% make.unique(.,sep="_")
sample_info = sample_info %>% select(sample,fastq1,fastq2,primer_5,primer_3,region,Batch_ID,expected.length,alias)
View(sample_info)
sample_info = sample_info %>% select(alias,fastq1,fastq2,primer_5,primer_3,region,Batch_ID,expected.length,sample)
colnames(sample_info)[1]
# Initialize a vector to store parsed headers
all_headers = data.frame(filename=NA, batchID=NA)
# Process each FASTQ file
for (file in fastq_files) {
header = read_first_fastq_header(file)
parsed_header = parse_header(header)
all_headers = rbind(data.frame(filename=file, batchID=parsed_header), all_headers)
}
# Count unique headers
theCount = table(all_headers$batchID)
theCount = data.frame(theCount)
theCount = data.frame(sequenceID=theCount$Var1, batch=paste0("Batch", 1:nrow(theCount)))
# Merge all_headers with theCount
all_headers = merge(all_headers, theCount, by.x="batchID", by.y="sequenceID")
# Keep only the file names and not the path of the files
all_headers$filename = sub(".*/", "", all_headers$filename)
# Rename columns
colnames(all_headers) = c("batchID", "fastq1", "Batch_ID")
all_headers$batchID = NULL
# Remove Batch_ID from sample_info if it exists
sample_info$Batch_ID = NULL
# Join all_headers with sample_info to add Batch_ID
sample_info = merge(sample_info, all_headers, by.x="fastq1", by.y="fastq1", all.x=TRUE)
# Now make the Sample column unique and add an alias column
sample_info$alias = as.character(sample_info$sample) %>% make.unique(.,sep="_")
sample_info = sample_info %>% select(alias,fastq1,fastq2,primer_5,primer_3,region,Batch_ID,expected.length,sample)
colnames(sample_info)[1] = "sampleZ"
colnames(sample_info)[9] = "alias"
colnames(sample_info)[1] = "sample"
write.csv(sample_info, file = "/Users/khaled/Desktop/sequencers_part2/Andrew/files_info_Batches.csv", row.names = FALSE, quote = FALSE)
?select
??select
#!usr/bin/env Rscript
# Function to read the first header from a FASTQ file
read_first_fastq_header = function(file_path) {
con = gzfile(file_path, "r")
first_header = readLines(con, n = 1)
close(con)
return(first_header)
}
# Function to extract and parse header parts
parse_header = function(header) {
parts = strsplit(header, ":")[[1]]
return(paste(parts[1:4], collapse = ":"))
}
fastq_dir = "/Users/khaled/Desktop/sequencers_part2/Andrew/"
fastq_files = list.files(fastq_dir, pattern = "\\.gz$", full.names = TRUE) # Get a list of FASTQ files in gz format
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
sample_info = read.csv("/Users/khaled/Desktop/sequencers_part2/Andrew/files_info.csv")
all_headers = data.frame(filename=NA, batchID=NA)
# Process each FASTQ file
for (file in fastq_files) {
header = read_first_fastq_header(file)
parsed_header = parse_header(header)
all_headers = rbind(data.frame(filename=file, batchID=parsed_header), all_headers)
}
# Count unique headers
theCount = table(all_headers$batchID)
theCount = data.frame(theCount)
theCount = data.frame(sequenceID=theCount$Var1, batch=paste0("Batch", 1:nrow(theCount)))
# Merge all_headers with theCount
all_headers = merge(all_headers, theCount, by.x="batchID", by.y="sequenceID")
# Keep only the file names and not the path of the files
all_headers$filename = sub(".*/", "", all_headers$filename)
# Rename columns
colnames(all_headers) = c("batchID", "fastq1", "Batch_ID")
all_headers$batchID = NULL
# Remove Batch_ID from sample_info if it exists
sample_info$Batch_ID = NULL
# Join all_headers with sample_info to add Batch_ID
sample_info = merge(sample_info, all_headers, by.x="fastq1", by.y="fastq1", all.x=TRUE)
# Now make the Sample column unique and add an alias column
sample_info$alias = make.unique(as.character(sample_info$sample),sep="_")
sample_info = data.frame(sample=sample_info$alias,
fastq1=sample_info$fastq1,
fastq2=sample_info$fastq2,
primer_5=sample_info$primer_5,
primer_3=sample_info$primer_3,
region=sample_info$region,
Batch_ID=sample_info$Batch_ID,
expected.length=sample_info$expected.length,
alias=sample_info$sample)
View(sample_info)
dim(sample_info)
sample_info$SampleNum = 1:dim(sample_info)[1]
write.csv(sample_info, file = "/Users/khaled/Desktop/sequencers_part2/Andrew/files_info_Batches.csv", row.names = FALSE, quote = FALSE)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("jsonlite"))
suppressMessages(library("dada2"))
jsonInput = jsonlite::fromJSON("/Users/khaled/Desktop/sequencers_part2/Andrew/favabean/Batch3-V3V5/figaro/trimParameters.json")
splitExpectedEE = as.data.frame(jsonInput$maxExpectedError) %>% as.matrix(.) %>% t(.)
colnames(splitExpectedEE) = c("R1EE","R2EE")
splitTrimPosition = as.data.frame(jsonInput$trimPosition) %>% as.matrix(.) %>% t(.)
colnames(splitTrimPosition) = c("R1Trim","R2Trim")
readRetentionPercent = jsonInput$readRetentionPercent
score = jsonInput$score
myJSONTable  =  cbind(splitExpectedEE,splitTrimPosition,readRetentionPercent,score) %>% as.data.frame(.)
inputFolder = "/Users/khaled/Desktop/sequencers_part2/Andrew/favabean/Batch3-V3V5/cutadapt"
cores = 10
most_coverage = myJSONTable %>% .[which(.$readRetentionPercent == max(.$readRetentionPercent)),]
result_row = most_coverage[which.max(most_coverage$score),] # If there are still ties, find row with maximum score
result_row
fnFs = sort(list.files(inputFolder, pattern="R1", full.names = TRUE))
fnFs
fnRs = sort(list.files(inputFolder, pattern="R2", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_R1_"), `[`, 1)
sample.names
filtFs <- file.path(paste0(outputFolder), "filtered", paste0(sample.names, "_filt_S1_L001_R1_001.fastq.gz"))
outputFolder = "~/Desktop/"
filtFs <- file.path(paste0(outputFolder), "filtered", paste0(sample.names, "_filt_S1_L001_R1_001.fastq.gz"))
filtRs <- file.path(paste0(outputFolder), "filtered", paste0(sample.names, "_filt_S1_L001_R2_001.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
print("Files detected, will perform filtering and trimming on the fastq files.")
out = filterAndTrim(fnFs, filtFs, fnRs, filtRs,
truncLen=c(result_row$R1Trim,result_row$R2Trim),
maxN=0,
maxEE=c(result_row$R1EE,result_row$R2EE), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=cores, matchIDs=TRUE)
