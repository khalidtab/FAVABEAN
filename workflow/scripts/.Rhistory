dada2R1fastq
theFolder = "~/Desktop/diabetes_DDI/favabean/data/favabean/Batch1-V34/"
fastqFolder = "~/Desktop/diabetes_DDI/favabean/data/favabean/Batch1-V34/dada2/filtered/"
# Denoised files
dada2denoisedR1 = list.files(theFolder,pattern="_DADA2Denoise-R1.RData",full.names = TRUE)
dada2R1titles = basename(dada2denoisedR1) %>% strsplit(.,"_DADA2Denoise-R1.RData") %>% unlist(.) %>% strsplit(.,"dada2_") %>% unlist(.) %>% Filter(function(x) nchar(x) > 0, .)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("dplyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("dada2"))
# Denoised files
dada2denoisedR1 = list.files(theFolder,pattern="_DADA2Denoise-R1.RData",full.names = TRUE)
dada2R1titles = basename(dada2denoisedR1) %>% strsplit(.,"_DADA2Denoise-R1.RData") %>% unlist(.) %>% strsplit(.,"dada2_") %>% unlist(.) %>% Filter(function(x) nchar(x) > 0, .)
dadaR1 = data.frame(title=dada2R1titles,denoiseR1=dada2denoisedR1)
dada2denoisedR2 = list.files(theFolder,pattern="_DADA2Denoise-R2.RData",full.names = TRUE)
dada2R2titles = basename(dada2denoisedR2) %>% strsplit(.,"_DADA2Denoise-R2.RData") %>% unlist(.) %>% strsplit(.,"dada2_") %>% unlist(.) %>% Filter(function(x) nchar(x) > 0, .)
dadaR2 = data.frame(title=dada2R1titles,denoiseR2=dada2denoisedR2)
dada2_denoise = left_join(dadaR1,dadaR2)
# fastq files
dada2FastqR1 = list.files(fastqFolder,pattern="R1_001.fastq.gz",full.names = TRUE)
dada2FastqR1titles = basename(dada2FastqR1) %>% strsplit(.,"_filt_S1_L001_R1_001.fastq.gz") %>% unlist(.) %>% strsplit(.,"_") %>% as.data.frame(.)
dada2FastqR1titles = dada2FastqR1titles[1,] %>% as.character(.)
dada2R1fastq = data.frame(title=dada2FastqR1titles,fastqR1=dada2FastqR1)
dada2FastqR2 = list.files(fastqFolder,pattern="R2_001.fastq.gz",full.names = TRUE)
dada2FastqR2titles = basename(dada2FastqR2) %>% strsplit(.,"_filt_S1_L001_R2_001.fastq.gz") %>% unlist(.) %>% strsplit(.,"_") %>% as.data.frame(.)
dada2FastqR2titles = dada2FastqR2titles[1,] %>% as.character(.)
dada2R2fastq = data.frame(title=dada2FastqR2titles,fastqR2=dada2FastqR2)
dada2_fastq = left_join(dada2R1fastq,dada2R2fastq)
dada2_files = left_join(dada2_fastq,dada2_denoise)
rm(dada2R2fastq,dada2FastqR2titles,dada2FastqR2,dada2R1fastq,dada2FastqR1titles,dada2FastqR1,dada2_denoise,dada2_fastq,dadaR2,dada2R2titles,dada2denoisedR2,dadaR1,dada2R1titles,dada2denoisedR1)
process_row <- function(row) {
# Load the R1 data
load(row['denoiseR1'])
dadaFs <- dadaDenoised
# Load the R2 data
load(row['denoiseR2'])
dadaRs <- dadaDenoised
# Perform the merging operation
print(paste("Now merging denoised R1 and R2 files from sample:", as.character(row['title'])))
mergers <- mergePairs(dadaFs, row['fastqR1'], dadaRs, row['fastqR2'], verbose = TRUE,minOverlap=5)
return(mergers)
}
mergers = apply(dada2_files, 1, process_row)
process_row <- function(row) {
# Load the R1 data
load(row['denoiseR1'])
dadaFs <- dadaDenoised
# Load the R2 data
load(row['denoiseR2'])
dadaRs <- dadaDenoised
# Perform the merging operation
print(paste("Now merging denoised R1 and R2 files from sample:", as.character(row['title'])))
mergers <- mergePairs(dadaFs, row['fastqR1'], dadaRs, row['fastqR2'], verbose = TRUE,minOverlap=5,verbose=TRUE)
return(mergers)
}
mergers = apply(dada2_files, 1, process_row)
process_row <- function(row) {
# Load the R1 data
load(row['denoiseR1'])
dadaFs <- dadaDenoised
# Load the R2 data
load(row['denoiseR2'])
dadaRs <- dadaDenoised
# Perform the merging operation
print(paste("Now merging denoised R1 and R2 files from sample:", as.character(row['title'])))
mergers = mergePairs(dadaFs, row['fastqR1'], dadaRs, row['fastqR2'], verbose = TRUE,minOverlap=5)
return(mergers)
}
process_row <- function(row) {
# Load the R1 data
load(row['denoiseR1'])
dadaFs <- dadaDenoised
# Load the R2 data
load(row['denoiseR2'])
dadaRs <- dadaDenoised
# Perform the merging operation
print(paste("Now merging denoised R1 and R2 files from sample:", as.character(row['title'])))
mergers = mergePairs(dadaFs, row['fastqR1'], dadaRs, row['fastqR2'], verbose = TRUE,minOverlap=5, mismatch=1)
return(mergers)
}
mergers = apply(dada2_files, 1, process_row)
process_row <- function(row) {
# Load the R1 data
load(row['denoiseR1'])
dadaFs <- dadaDenoised
# Load the R2 data
load(row['denoiseR2'])
dadaRs <- dadaDenoised
# Perform the merging operation
print(paste("Now merging denoised R1 and R2 files from sample:", as.character(row['title'])))
mergers = mergePairs(dadaFs, row['fastqR1'], dadaRs, row['fastqR2'], verbose = TRUE,minOverlap=5, mismatch=10)
return(mergers)
}
# Apply the function to each row of the dataframe
mergers = apply(dada2_files, 1, process_row)
print("Sample merging completed.")
seqtab = makeSequenceTable(mergers) %>% as.data.frame(.)
seqtab2 = data.frame(SampleID=dada2_files$title,seqtab)
write_tsv(seqtab2,file=paste0(theFolder,"/seqtab.tsv"),col_names=TRUE)
?makeSequenceTable()
process_forward <- function(row) {
# Load the R1 data
load(row['denoiseR1'])
dadaFs <- dadaDenoised
# Perform the merging operation
print(paste("Now merging denoised R1 and R2 files from sample:", as.character(row['title'])))
forwardOnly = makeSequenceTable(dadaFs)
return(forwardOnly)
}
forwardOnly = apply(dada2_files, 1, process_forward)
process_forward <- function(row) {
# Load the R1 data
load(row['denoiseR1'])
dadaFs <- dadaDenoised
# Perform the merging operation
print(paste("Processing forward reads of:", as.character(row['title'])))
forwardOnly = makeSequenceTable(dadaFs)
return(forwardOnly)
}
forwardOnly = apply(dada2_files, 1, process_forward)
seqtab3 = makeSequenceTable(forwardOnly) %>% as.data.frame(.)
View(seqtab3)
seqtab4 = data.frame(SampleID=dada2_files$title,seqtab3)
View(seqtab4)
write_tsv(seqtab4,file=paste0(theFolder,"/seqtab_forwardOnly.tsv"),col_names=TRUE)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("dada2"))
outputFile = "~/Desktop/diabetes_DDI/favabean/data/"
cores = 20
inputfile = "~/Desktop/diabetes_DDI/favabean/data/favabean/"
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
myparameter = "V34"
inputfiles2 = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.]
inputfiles2
inputfiles2
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
inputfiles2 = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)
inputfiles2
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
inputfiles2 = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
pairedfiles
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE)
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
print("Merging sequence tables…")
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE)
pairedfiles  = pairedfiles  %>% mergeSequenceTables(tables=.,tryRC = TRUE)
?mergeSequenceTables
pairedfiles  = pairedfiles  %>% try(mergeSequenceTables(tables=.,tryRC = TRUE))
?try
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
print("Merging sequence tables…")
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE)
pairedfiles  = pairedfiles  %>% try(mergeSequenceTables(tables=.,tryRC = TRUE),silent=FALSE)
pairedfiles
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
print("Merging sequence tables…")
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE)
pairedfiles  = pairedfiles  %>% try(mergeSequenceTables(tables=.,tryRC = TRUE),silent=FALSE)
print("Done with merging sequence tables. Table format modification to accomodate chimera removal starts now…")
forwardfiles = as.data.frame(forwardfiles) %>% pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")
pairedfiles  = as.data.frame(pairedfiles) %>% pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")
pairedfiles
forwardfiles = as.data.frame(forwardfiles) %>% pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
print("Merging sequence tables…")
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE)
pairedfiles  = pairedfiles  %>% try(mergeSequenceTables(tables=.,tryRC = TRUE),silent=FALSE)
print("Done with merging sequence tables. Table format modification to accomodate chimera removal starts now…")
forwardfiles = as.data.frame(forwardfiles) %>% pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")
pairedfiles  = as.data.frame(pairedfiles)  %>% pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")
as.data.frame(pairedfiles)
pairedfiles
as.data.frame(pairedfiles)
pairedfiles  = try(as.data.frame(pairedfiles)  %>% pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence"))
pairedfiles  = try(as.data.frame(pairedfiles)  %>% try(pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")))
pairedfiles
seqtab_noChim_forward =  removeBimeraDenovo(forwardfiles, multithread =  TRUE, verbose=TRUE, method = "pooled")
seqtab_noChim         =  try(removeBimeraDenovo(pairedfiles , multithread =  TRUE, verbose=TRUE, method = "pooled"))
forwardfiles = forwardfiles %>% .[,colnames(.) %in% seqtab_noChim$sequence]
forwardfiles = forwardfiles %>% .[,colnames(.) %in% seqtab_noChim_forward$sequence]
pairedfiles  = pairedfiles  %>% .[,colnames(.) %in% seqtab_noChim$sequence]
pairedfiles  = pairedfiles  %>% try(.[,colnames(.) %in% seqtab_noChim$sequence])
pairedfiles
save(forwardfiles, pairedfiles, file = paste0("data/favabean/",myparameter,"_chimeraRemoved.RObjects"), envir = .GlobalEnv)
save(forwardfiles, pairedfiles, file = paste0("~/Desktop/diabetes_DDI/favabean/data/favabean/",myparameter,"_chimeraRemoved.RObjects"), envir = .GlobalEnv)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("dada2"))
inputFile = "~/Desktop/diabetes_DDI/favabean/data/favabean/V34_chimeraRemoved.RObjects"
cores = 20
load(inputFile)
print("starting collapse of ASVs…")
View(forwardfiles)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("dada2"))
cores = 20
inputfile = "~/Desktop/diabetes_DDI/favabean/data/favabean/"
parameter = "V34"
myparameter = "V34"
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
print("Merging sequence tables…")
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE)
pairedfiles  = pairedfiles  %>% try(mergeSequenceTables(tables=.,tryRC = TRUE),silent=FALSE)
View(forwardfiles)
forwardfiles = as.data.frame(forwardfiles) %>% pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")
pairedfiles  = try(as.data.frame(pairedfiles)  %>% try(pivot_longer(cols=colnames(.),values_to = "abundance",names_to = "sequence")))
View(forwardfiles)
seqtab_noChim_forward =  removeBimeraDenovo(forwardfiles, multithread =  TRUE, verbose=TRUE, method = "pooled")
seqtab_noChim         =  try(removeBimeraDenovo(pairedfiles , multithread =  TRUE, verbose=TRUE, method = "pooled"))
View(seqtab_noChim_forward)
forwardfiles2 = forwardfiles %>% .[,colnames(.) %in% seqtab_noChim_forward$sequence]
View(forwardfiles2)
?removeBimeraDenovo
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
print("Merging sequence tables…")
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE)
pairedfiles  = pairedfiles  %>% try(mergeSequenceTables(tables=.,tryRC = TRUE),silent=FALSE)
print("Done with merging sequence tables. Table format modification to accomodate chimera removal starts now…")
forwardfiles = as.data.frame(forwardfiles)
seqtab_noChim_forward =  removeBimeraDenovo(forwardfiles, multithread =  TRUE, verbose=TRUE, method = "pooled")
forwardfiles
View(forwardfiles)
removeBimeraDenovo(colnames(forwardfiles), multithread =  TRUE, verbose=TRUE, method = "pooled")
removeBimeraDenovo(as.matrix(colnames(forwardfiles)), multithread =  TRUE, verbose=TRUE, method = "pooled")
removeBimeraDenovo(as.matrix(forwardfiles), multithread =  TRUE, verbose=TRUE, method = "pooled")
inputfiles = list.files(inputfile,pattern = "seqtab", full.names = TRUE, recursive = TRUE)
forwardfiles = inputfiles %>% grepl(myparameter,x=.) %>% inputfiles[.] %>% grepl("seqtab_forwardOnly",x=.)  %>% inputfiles[.]
pairedfiles = inputfiles[-which(inputfiles %in% forwardfiles)]
process_file <- function(path) {
newTable <- read_tsv(path) %>%
as.data.frame()
rownames(newTable) <- newTable[, 1]
newTable[, 1] <- NULL
newTable = as.matrix(newTable)
return(newTable)
}
forwardfiles = base::sapply(forwardfiles, process_file,simplify=TRUE)
pairedfiles  = base::sapply(pairedfiles , process_file,simplify=TRUE)
print("Merging sequence tables, then performing chimera removal")
forwardfiles = forwardfiles %>% mergeSequenceTables(tables=.,tryRC = TRUE) %>% removeBimeraDenovo(., multithread =  TRUE, verbose=TRUE, method = "pooled")
pairedfiles  = pairedfiles  %>% try(mergeSequenceTables(tables=.,tryRC = TRUE),silent=FALSE) %>% try(removeBimeraDenovo(., multithread =  TRUE, verbose=TRUE, method = "pooled"))
print("Chimeras removed")
save(forwardfiles, pairedfiles, file = paste0("data/favabean/",myparameter,"_chimeraRemoved.RObjects"), envir = .GlobalEnv)
save(forwardfiles, pairedfiles, file = paste0("~/Desktop/diabetes_DDI/favabean/data/favabean/",myparameter,"_chimeraRemoved.RObjects"), envir = .GlobalEnv)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("dada2"))
inputFile = "~/Desktop/diabetes_DDI/favabean/data/favabean/V34_chimeraRemoved.RObjects"
cores = 20
load(inputFile)
View(forwardfiles)
condensed_table_forward = collapseNoMismatch(forwardfiles, minOverlap = 20, orderBy = "abundance", identicalOnly = FALSE, vec = TRUE, band = -1, verbose = TRUE)
View(forwardfiles)
SampleIDs = rownames(condensed_table_forward)
condensed_table = as.data.frame(condensed_table_forward)
condensed_table = cbind(SampleIDs,condensed_table)
condensed_table = t(condensed_table) %>% as.data.frame(.)
condensed_table = cbind(rownames(condensed_table),condensed_table)
opt = NULL
opt$output = "~/Desktop/diabetes_DDI/favabean/data/favabean/forward_collapsed.tsv"
write_tsv(condensed_table,opt$output,col_names = FALSE)
suppressMessages(library("optparse"))
suppressMessages(library("readr"))
suppressMessages(library("tidyr"))
suppressMessages(library("magrittr"))
suppressMessages(library("dada2"))
opt = NULL
opt$input = "/Users/khaled/Desktop/diabetes_DDI/favabean/data/favabean/forward_collapsed.tsv"
opt$database = "/Users/khaled/Desktop/diabetes_DDI/favabean/data/resources/eHOMD_ref.fa.gz"
opt$species = "/Users/khaled/Desktop/diabetes_DDI/favabean/data/resources/eHOMD_species.fa.gz"
myCores = 20
inputFile = opt$input
myDatabase = opt$database
mySpecies = opt$species
inputMatrix = read_tsv(inputFile) %>% as.data.frame(.)
ASVs = inputMatrix$SampleIDs
print("Beginning assignment up to genus level.")
taxa3 = dada2::assignTaxonomy(ASVs, myDatabase,verbose=TRUE, tryRC = TRUE, multithread = FALSE)
print("Taxonomy assignment up to genus level is completed.")
print("Beginning assignment up to species level.")
taxa4 = dada2::assignSpecies(taxa3,mySpecies,tryRC = TRUE)
print("Taxonomy assignment up to species level is completed.")
taxa3 = cbind(rownames(taxa3),taxa3) %>% as.data.frame(.)
taxa4 = cbind(rownames(taxa4),taxa4) %>% as.data.frame(.)
taxa5 = dplyr::left_join(taxa3,taxa4)
taxa5[is.na(taxa5)] = ""
taxonomy = paste0("k__",taxa5$Kingdom,"; p__",taxa5$Phylum,"; c__",taxa5$Class,"; o__",taxa5$Order,"; f__",taxa5$Family,"; g__",taxa5$Genus,"; s__",taxa5$Species)
inputMatrix2 = cbind(inputMatrix,taxonomy)
OTU_IDs = rownames(inputMatrix2)
inputMatrix3 = cbind(paste0("OTU",OTU_IDs),inputMatrix2)
colnames(inputMatrix3)[1] = "#SampleID"
taxonomy = data.frame(OTU_ID = inputMatrix3$`#SampleID`, Sequences = inputMatrix3$SampleIDs, Taxonomy = inputMatrix3$taxonomy)
inputMatrix3 = inputMatrix3 %>% .[,-which(colnames(.) %in% c("SampleIDs","taxonomy"))]
View(taxonomy)
View(inputMatrix3)
myOutput = "~/Desktop/diabetes_DDI/favabean/data/favabean/taxonomyTable.tsv"
taxonomyOutput = "~/Desktop/diabetes_DDI/favabean/data/favabean/taxa.tsv"
write_tsv(inputMatrix3,myOutput)
write_tsv(taxonomy,taxonomyOutput)
library(dplyr)
mydataframe = read_tsv("/Users/khaled/Desktop/diabetes_DDI/favabean/data/favabean/taxonomyTable.tsv")
View(mydataframe)
result <- mydataframe %>%
group_by(`#SampleID`) %>%
summarise(across(everything(), sum, na.rm = TRUE))
View(result)
write_tsv(result,"/Users/khaled/Desktop/diabetes_DDI/favabean/data/favabean/taxonomyTableCondsensed.tsv")
# Function to read the first header from a FASTQ file
read_first_fastq_header = function(file_path) {
con = file(file_path, "r")
first_header = readLines(con, n = 1)
close(con)
return(first_header)
}
# Function to extract and parse header parts
parse_header = function(header) {
parts = strsplit(header, ":")[[1]]
return(paste(parts[1:4], collapse = ":"))
}
fastq_dir = "~/diabetes_DDI/favabean/data" # Directory containing your FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.fastq$", full.names = TRUE) # Get a list of FASTQ files
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
sample_info = read.csv("/data/files_info.csv")
fastq_dir = "~/diabetes_DDI/favabean/data" # Directory containing your FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.fastq$", full.names = TRUE) # Get a list of FASTQ files
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
sample_info = read.csv("~/diabetes_DDI/favabean/data/files_info.csv")
fastq_dir = "~/Desktop/diabetes_DDI/favabean/data" # Directory containing your FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.fastq$", full.names = TRUE) # Get a list of FASTQ files
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
fastq_dir = "~/Desktop/diabetes_DDI/favabean/data/" # Directory containing your FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.fastq$", full.names = TRUE) # Get a list of FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.fastq.gz$", full.names = TRUE) # Get a list of FASTQ files
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
sample_info = read.csv("~/Desktop/diabetes_DDI/favabean/data/")
sample_info = read.csv("~/Desktop/diabetes_DDI/favabean/data/files_info.csv")
all_headers = data.frame(filename=NA, batchID=NA)
file = fastq_files[1]
library("R.utils")
?gunzip
hi = gunzip(file,remove=TRUE)
hi
library("R.utils")
read_first_fastq_header = function(file_path) {
fastqFile = gunzip(file,remove=TRUE)
con = file(fastqFile, "r")
first_header = readLines(con, n = 1)
close(con)
file.remove(fastqFile)
return(first_header)
}
for (file in fastq_files) {
header = read_first_fastq_header(file)
parsed_header = parse_header(header)
all_headers = rbind(data.frame(filename=file, batchID=parsed_header), all_headers)
}
# Function to read the first header from a FASTQ file
read_first_fastq_header = function(file_path) {
fastqFile = gunzip(file,remove=TRUE)
con = file(fastqFile, "r")
first_header = readLines(con, n = 1)
close(con)
file.remove(fastqFile)
return(first_header)
}
# Function to extract and parse header parts
parse_header = function(header) {
parts = strsplit(header, ":")[[1]]
return(paste(parts[1:4], collapse = ":"))
}
fastq_dir = "~/Desktop/diabetes_DDI/favabean/data/" # Directory containing your FASTQ files
fastq_files = list.files(fastq_dir, pattern = "\\.fastq.gz$", full.names = TRUE) # Get a list of FASTQ files
fastq_files = fastq_files[grep("R1", fastq_files)] # Keep only R1 files
sample_info = read.csv("~/Desktop/diabetes_DDI/favabean/data/files_info.csv")
# Initialize a vector to store parsed headers
all_headers = data.frame(filename=NA, batchID=NA)
# Process each FASTQ file
for (file in fastq_files) {
header = read_first_fastq_header(file)
parsed_header = parse_header(header)
all_headers = rbind(data.frame(filename=file, batchID=parsed_header), all_headers)
}
theCount = table(all_headers$batchID)
theCount = data.frame(theCount)
theCount = data.frame(sequenceID=theCount$Var1, batch=paste0("Batch", 1:nrow(theCount)))
theCount
all_headers = merge(all_headers, theCount, by.x="batchID", by.y="sequenceID")
all_headers$filename = sub(".*/", "", all_headers$filename)
# Rename columns
colnames(all_headers) = c("batchID", "fastq1", "Batch_ID")
all_headers$batchID = NULL
# Remove Batch_ID from sample_info if it exists
sample_info$Batch_ID = NULL
# Join all_headers with sample_info to add Batch_ID
sample_info = merge(sample_info, all_headers, by.x="fastq1", by.y="fastq1", all.x=TRUE)
write.csv(sample_info, file = "~/Desktop/diabetes_DDI/favabean/data/files_info.csv", row.names = FALSE, quote = FALSE)
